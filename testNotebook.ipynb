{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training data\n",
    "\n",
    "train_data = pd.read_csv('train.csv', delimiter=';')\n",
    "#train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# claim variables\n",
    "\n",
    "train_data['claim_amount'] = train_data['claim_amount'].str.replace(',','.').astype('float64')\n",
    "\n",
    "train_data['claim_date_registered'] = pd.to_datetime(train_data['claim_date_registered'], format='%Y%m%d')\n",
    "\n",
    "train_data['claim_date_occured'] = pd.to_datetime(train_data['claim_date_occured'], format='%Y%m%d')\n",
    "\n",
    "mask_night = (train_data['claim_time_occured'] >= 2200) | (train_data['claim_time_occured'] <= 700)\n",
    "train_data.loc[~mask_night, 'claim_time_occured'] = 0\n",
    "train_data.loc[mask_night, 'claim_time_occured'] = 1\n",
    "\n",
    "postal_code_counts = train_data['claim_postal_code'].value_counts()\n",
    "train_data = train_data.merge(postal_code_counts, how='left', left_on='claim_postal_code', right_index=True)\n",
    "\n",
    "train_data['claim_alcohol'].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "train_data['claim_language'].fillna(\"MISSING\", inplace=True)\n",
    "mask = train_data['claim_language'] == 1.0\n",
    "train_data.loc[mask, 'claim_language'] = \"LANG A\"\n",
    "mask = train_data['claim_language'] == 2.0\n",
    "train_data.loc[mask, 'claim_language'] = \"LANG B\"\n",
    "\n",
    "train_data['claim_vehicle_id'].fillna(\"MISSING\", inplace=True)\n",
    "claim_vehicle_id_count = train_data['claim_vehicle_id'].value_counts()\n",
    "claim_vehicle_id_count[\"MISSING\"] = 0\n",
    "train_data = train_data.merge(claim_vehicle_id_count, how='left', \n",
    "                              left_on='claim_vehicle_id', right_index=True)\n",
    "\n",
    "train_data['claim_vehicle_brand'].fillna('MISSING', inplace=True)\n",
    "claim_vehicle_brand_counts = train_data['claim_vehicle_brand'].value_counts()\n",
    "claim_vehicle_brand_counts['MISSING'] = 0\n",
    "train_data = train_data.merge(claim_vehicle_brand_counts, how='left', \n",
    "                              left_on='claim_vehicle_brand', right_index=True)\n",
    "\n",
    "\n",
    "train_data['claim_vehicle_type'].fillna('MISSING', inplace=True)\n",
    "\n",
    "train_data['claim_vehicle_date_inuse'].fillna(190001, inplace=True)\n",
    "train_data['claim_vehicle_date_inuse'] = train_data['claim_vehicle_date_inuse'].astype(int)\n",
    "mask = (train_data['claim_vehicle_date_inuse'] > 220000)\n",
    "train_data.loc[mask, 'claim_vehicle_date_inuse'] = 190001\n",
    "train_data['claim_vehicle_date_inuse'] = pd.to_datetime(train_data['claim_vehicle_date_inuse'].astype(str), \n",
    "                                                        format='%Y%m')\n",
    "\n",
    "train_data['claim_vehicle_cyl'].fillna(10000, inplace=True)\n",
    "\n",
    "train_data['claim_vehicle_load'].fillna(500, inplace=True)\n",
    "\n",
    "train_data['claim_vehicle_fuel_type'].fillna('MISSING', inplace=True)\n",
    "mask = train_data['claim_vehicle_fuel_type'] == 1.0\n",
    "train_data.loc[mask, 'claim_vehicle_fuel_type'] = \"FUEL A\"\n",
    "mask = train_data['claim_vehicle_fuel_type'] == 2.0\n",
    "train_data.loc[mask, 'claim_vehicle_fuel_type'] = \"FUEL B\"\n",
    "\n",
    "train_data['claim_vehicle_power'].fillna(1000, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy variables\n",
    "\n",
    "policy_holder_id_count = train_data['policy_holder_id'].value_counts()\n",
    "train_data = train_data.merge(policy_holder_id_count, how='left', \n",
    "                              left_on='policy_holder_id', right_index=True)\n",
    "\n",
    "train_data['policy_holder_postal_code'].fillna(0, inplace=True)\n",
    "policy_holder_postal_code_counts = train_data['policy_holder_postal_code'].value_counts()\n",
    "policy_holder_postal_code_counts.loc[0] = 0\n",
    "train_data = train_data.merge(policy_holder_postal_code_counts, how='left', \n",
    "                              left_on='policy_holder_postal_code', right_index=True)\n",
    "\n",
    "train_data['policy_holder_year_birth'].fillna(1800, inplace=True)\n",
    "\n",
    "train_data['policy_holder_expert_id'].fillna(\"MISSING\", inplace=True)\n",
    "policy_holder_expert_id_count = train_data['policy_holder_expert_id'].value_counts()\n",
    "policy_holder_expert_id_count['MISSING'] = 0\n",
    "train_data = train_data.merge(policy_holder_expert_id_count, how='left', \n",
    "                              left_on='policy_holder_expert_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver variables\n",
    "\n",
    "driver_id_count = train_data['driver_id'].value_counts()\n",
    "train_data = train_data.merge(driver_id_count, how='left', \n",
    "                              left_on='driver_id', right_index=True)\n",
    "\n",
    "train_data['driver_postal_code'].fillna(0, inplace=True)\n",
    "driver_postal_code_count = train_data['driver_postal_code'].value_counts()\n",
    "driver_postal_code_count.loc[0] = 0\n",
    "train_data = train_data.merge(driver_postal_code_count, how='left', \n",
    "                              left_on='driver_postal_code', right_index=True)\n",
    "\n",
    "train_data['driver_year_birth'].fillna(1801, inplace=True)\n",
    "\n",
    "train_data['driver_expert_id'].fillna(\"MISSING\", inplace=True)\n",
    "driver_expert_id_count = train_data['driver_expert_id'].value_counts()\n",
    "driver_expert_id_count['MISSING'] = 0\n",
    "train_data = train_data.merge(driver_expert_id_count, how='left', \n",
    "                              left_on='driver_expert_id', right_index=True)\n",
    "\n",
    "train_data['driver_vehicle_id'].fillna(\"MISSING\", inplace=True)\n",
    "driver_vehicle_id_count = train_data['driver_vehicle_id'].value_counts()\n",
    "driver_vehicle_id_count[\"MISSING\"] = 0\n",
    "train_data = train_data.merge(driver_vehicle_id_count, how='left', \n",
    "                              left_on='driver_vehicle_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party 1st variables\n",
    "\n",
    "train_data['third_party_1_id'].fillna(\"MISSING\", inplace=True)\n",
    "third_party_1_id_count = train_data['third_party_1_id'].value_counts()\n",
    "third_party_1_id_count[\"MISSING\"] = 0\n",
    "train_data = train_data.merge(third_party_1_id_count, how='left', \n",
    "                              left_on='third_party_1_id', right_index=True)\n",
    "\n",
    "train_data['third_party_1_postal_code'].fillna(0, inplace=True)\n",
    "third_party_1_postal_code_count = train_data['third_party_1_postal_code'].value_counts()\n",
    "third_party_1_postal_code_count[0] = 0\n",
    "train_data = train_data.merge(third_party_1_postal_code_count, how='left', \n",
    "                              left_on='third_party_1_postal_code', right_index=True)\n",
    "\n",
    "train_data['third_party_1_injured'].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "train_data['third_party_1_vehicle_type'].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "train_data['third_party_1_form'].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "train_data['third_party_1_year_birth'].fillna(1802, inplace=True)\n",
    "\n",
    "train_data['third_party_1_country'].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "train_data['third_party_1_vehicle_id'].fillna(\"MISSING\", inplace=True)\n",
    "third_party_1_vehicle_id_count = train_data['third_party_1_vehicle_id'].value_counts()\n",
    "third_party_1_vehicle_id_count[\"MISSING\"] = 0\n",
    "train_data = train_data.merge(third_party_1_vehicle_id_count, how='left', \n",
    "                              left_on='third_party_1_vehicle_id', right_index=True)\n",
    "\n",
    "train_data['third_party_1_expert_id'].fillna(\"MISSING\", inplace=True)\n",
    "third_party_1_expert_id_count = train_data['third_party_1_expert_id'].value_counts()\n",
    "third_party_1_expert_id_count[\"MISSING\"] = 0\n",
    "train_data = train_data.merge(third_party_1_expert_id_count, how='left', \n",
    "                 left_on='third_party_1_expert_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party rest of variables\n",
    "\n",
    "mask = train_data['third_party_2_id'].isna()\n",
    "train_data.loc[mask, 'third_party_2_id'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_id'] = 1\n",
    "\n",
    "mask = train_data['third_party_2_postal_code'].isna()\n",
    "train_data.loc[mask, 'third_party_2_postal_code'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_postal_code'] = 1\n",
    "\n",
    "mask = train_data['third_party_2_injured'].isna()\n",
    "train_data.loc[mask, 'third_party_2_injured'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_injured'] = 1\n",
    "\n",
    "mask = train_data['third_party_2_vehicle_type'].isna()\n",
    "train_data.loc[mask, 'third_party_2_vehicle_type'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_vehicle_type'] = 1\n",
    "\n",
    "mask = train_data['third_party_2_form'].isna()\n",
    "train_data.loc[mask, 'third_party_2_form'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_form'] = 1\n",
    "\n",
    "mask = train_data['third_party_2_year_birth'].isna()\n",
    "train_data.loc[mask, 'third_party_2_year_birth'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_year_birth'] = 1\n",
    "\n",
    "mask = train_data['third_party_2_country'].isna()\n",
    "train_data.loc[mask, 'third_party_2_country'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_country'] = 1\n",
    "\n",
    "mask = train_data['third_party_2_vehicle_id'].isna()\n",
    "train_data.loc[mask, 'third_party_2_vehicle_id'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_vehicle_id'] = 1\n",
    "\n",
    "mask = train_data['third_party_2_expert_id'].isna()\n",
    "train_data.loc[mask, 'third_party_2_expert_id'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_expert_id'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_id'].isna()\n",
    "train_data.loc[mask, 'third_party_3_id'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_id'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_postal_code'].isna()\n",
    "train_data.loc[mask, 'third_party_3_postal_code'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_postal_code'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_injured'].isna()\n",
    "train_data.loc[mask, 'third_party_3_injured'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_injured'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_vehicle_type'].isna()\n",
    "train_data.loc[mask, 'third_party_3_vehicle_type'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_vehicle_type'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_form'].isna()\n",
    "train_data.loc[mask, 'third_party_3_form'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_form'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_year_birth'].isna()\n",
    "train_data.loc[mask, 'third_party_3_year_birth'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_year_birth'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_country'].isna()\n",
    "train_data.loc[mask, 'third_party_3_country'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_country'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_vehicle_id'].isna()\n",
    "train_data.loc[mask, 'third_party_3_vehicle_id'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_vehicle_id'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_expert_id'].isna()\n",
    "train_data.loc[mask, 'third_party_3_expert_id'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_expert_id'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repair variables\n",
    "\n",
    "train_data['repair_id'].fillna(\"MISSING\", inplace=True)\n",
    "repair_id_count = train_data['repair_id'].value_counts()\n",
    "repair_id_count[\"MISSING\"] = 0\n",
    "train_data = train_data.merge(repair_id_count, how='left', \n",
    "                 left_on='repair_id', right_index=True)\n",
    "\n",
    "train_data['repair_postal_code'].fillna(0, inplace=True)\n",
    "repair_postal_code_count = train_data['repair_postal_code'].value_counts()\n",
    "repair_postal_code_count[0] = 0\n",
    "train_data = train_data.merge(repair_postal_code_count, how='left', \n",
    "                 left_on='repair_postal_code', right_index=True)\n",
    "\n",
    "train_data['repair_form'].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "train_data['repair_year_birth'].fillna(1804, inplace=True)\n",
    "\n",
    "train_data['repair_country'].fillna(\"MISSING\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final variables\n",
    "\n",
    "train_data['policy_date_start'].fillna(180501, inplace=True)\n",
    "train_data['policy_date_start'] = pd.to_datetime(train_data['policy_date_start'].astype(int).astype(str),\n",
    "                                                 format='%Y%m')\n",
    "\n",
    "train_data['policy_date_next_expiry'].fillna(180501, inplace=True)\n",
    "train_data['policy_date_next_expiry'] = pd.to_datetime(train_data['policy_date_next_expiry'].astype(int).astype(str),\n",
    "                                                       format='%Y%m')\n",
    "\n",
    "train_data['policy_date_last_renewed'].fillna(180501, inplace=True)\n",
    "train_data['policy_date_last_renewed'] = pd.to_datetime(train_data['policy_date_last_renewed'].astype(int).astype(str),\n",
    "                                                        format='%Y%m')\n",
    "\n",
    "train_data['policy_premium_100'].fillna(200, inplace=True)\n",
    "\n",
    "train_data['policy_coverage_1000'].fillna(300, inplace=True)\n",
    "\n",
    "train_data['policy_coverage_type'].fillna(\"MISSING\", inplace=True)\n",
    "policy_coverage_type_count = train_data['policy_coverage_type'].value_counts()\n",
    "policy_coverage_type_count[\"MISSING\"] = 0\n",
    "train_data = train_data.merge(policy_coverage_type_count, how='left', \n",
    "                 left_on='policy_coverage_type', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_cols = train_data.filter(regex='third_party_2|third_party_3').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop cols for now\n",
    "\n",
    "dropcols = ['claim_id', 'claim_postal_code_x', 'claim_vehicle_id_x', 'claim_vehicle_brand_x',\n",
    "       'policy_holder_id_x', 'policy_holder_postal_code_x',\n",
    "       'policy_holder_expert_id_x', 'driver_id_x', 'driver_postal_code_x',\n",
    "       'driver_expert_id_x', 'driver_vehicle_id_x', 'third_party_1_id_x',\n",
    "       'third_party_1_postal_code_x', 'third_party_1_vehicle_id_x',\n",
    "       'third_party_1_expert_id_x', 'repair_id_x', 'repair_postal_code_x',\n",
    "       'claim_date_registered', 'claim_date_occured', 'claim_vehicle_date_inuse',\n",
    "       'policy_date_start', 'policy_date_next_expiry', 'policy_date_last_renewed', 'policy_coverage_type_x']\n",
    "\n",
    "clean_data = train_data.drop(columns=dropcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target and covariates\n",
    "\n",
    "indices = clean_data[(clean_data['fraud'] == 'Y') & (clean_data['claim_amount'] < 500)].index\n",
    "double = clean_data[(clean_data['fraud'] == 'Y') & (clean_data['claim_amount'] > 2500)]\n",
    "\n",
    "oversampled_data = pd.concat([clean_data, double])\n",
    "\n",
    "# target and covariates\n",
    "y = clean_data.drop(indices)['fraud']\n",
    "X = clean_data.drop(indices).drop(columns=['fraud', 'claim_amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast correct dtype\n",
    "\n",
    "X[third_cols] = X[third_cols].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save for sanity check\n",
    "\n",
    "mask = (X.dtypes == object)\n",
    "train_obj = X.dtypes.loc[mask].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode vars\n",
    "\n",
    "encoded_covariates = pd.get_dummies(X)\n",
    "encoded_target = pd.get_dummies(y)['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=250)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run model\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=250)\n",
    "rf.fit(encoded_covariates, encoded_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save for sanity check\n",
    "\n",
    "train_cols = encoded_covariates.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test data\n",
    "\n",
    "test_data = pd.read_csv('test.csv', delimiter=';')\n",
    "#test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# claim variables\n",
    "\n",
    "#train_data['claim_amount'] = train_data['claim_amount'].str.replace(',','.').astype('float64')\n",
    "\n",
    "test_data['claim_date_registered'] = pd.to_datetime(test_data['claim_date_registered'], format='%Y%m%d')\n",
    "\n",
    "test_data['claim_date_occured'] = pd.to_datetime(test_data['claim_date_occured'], format='%Y%m%d')\n",
    "\n",
    "mask_night = (test_data['claim_time_occured'] >= 2200) | (test_data['claim_time_occured'] <= 700)\n",
    "test_data.loc[~mask_night, 'claim_time_occured'] = 0\n",
    "test_data.loc[mask_night, 'claim_time_occured'] = 1\n",
    "\n",
    "# postal_code_counts = train_data['claim_postal_code'].value_counts()\n",
    "test_data = test_data.merge(postal_code_counts, how='left', left_on='claim_postal_code', right_index=True)\n",
    "\n",
    "test_data['claim_alcohol'].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "test_data['claim_language'].fillna(\"MISSING\", inplace=True)\n",
    "mask = test_data['claim_language'] == 1.0\n",
    "test_data.loc[mask, 'claim_language'] = \"LANG A\"\n",
    "mask = test_data['claim_language'] == 2.0\n",
    "test_data.loc[mask, 'claim_language'] = \"LANG B\"\n",
    "\n",
    "test_data['claim_vehicle_id'].fillna(\"MISSING\", inplace=True)\n",
    "#claim_vehicle_id_count = train_data['claim_vehicle_id'].value_counts()\n",
    "#claim_vehicle_id_count[\"MISSING\"] = 0\n",
    "test_data = test_data.merge(claim_vehicle_id_count, how='left', \n",
    "                              left_on='claim_vehicle_id', right_index=True)\n",
    "\n",
    "test_data['claim_vehicle_brand'].fillna('MISSING', inplace=True)\n",
    "#claim_vehicle_brand_counts = train_data['claim_vehicle_brand'].value_counts()\n",
    "#claim_vehicle_brand_counts['MISSING'] = 0\n",
    "test_data = test_data.merge(claim_vehicle_brand_counts, how='left', \n",
    "                              left_on='claim_vehicle_brand', right_index=True)\n",
    "\n",
    "test_data['claim_vehicle_date_inuse'].fillna(190001.0, inplace=True)\n",
    "mask = (test_data['claim_vehicle_date_inuse'] > 210001.0)\n",
    "test_data.loc[mask, 'claim_vehicle_date_inuse'] = 190001.0\n",
    "test_data['claim_vehicle_date_inuse'] = pd.to_datetime(test_data['claim_vehicle_date_inuse'].astype(int).astype(str), \n",
    "                                                        format='%Y%m')\n",
    "\n",
    "test_data['claim_vehicle_cyl'].fillna(10000, inplace=True)\n",
    "\n",
    "test_data['claim_vehicle_load'].fillna(500, inplace=True)\n",
    "\n",
    "test_data['claim_vehicle_fuel_type'].fillna('MISSING', inplace=True)\n",
    "mask = test_data['claim_vehicle_fuel_type'] == 1.0\n",
    "test_data.loc[mask, 'claim_vehicle_fuel_type'] = \"FUEL A\"\n",
    "mask = test_data['claim_vehicle_fuel_type'] == 2.0\n",
    "test_data.loc[mask, 'claim_vehicle_fuel_type'] = \"FUEL B\"\n",
    "\n",
    "test_data['claim_vehicle_type'].fillna('MISSING', inplace=True)\n",
    "\n",
    "test_data['claim_vehicle_power'].fillna(1000, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy variables\n",
    "\n",
    "#policy_holder_id_count = train_data['policy_holder_id'].value_counts()\n",
    "test_data = test_data.merge(policy_holder_id_count, how='left', \n",
    "                              left_on='policy_holder_id', right_index=True)\n",
    "\n",
    "test_data['policy_holder_postal_code'].fillna(0, inplace=True)\n",
    "#policy_holder_postal_code_counts = train_data['policy_holder_postal_code'].value_counts()\n",
    "#policy_holder_postal_code_counts.loc[0] = 0\n",
    "test_data = test_data.merge(policy_holder_postal_code_counts, how='left', \n",
    "                              left_on='policy_holder_postal_code', right_index=True)\n",
    "\n",
    "test_data['policy_holder_year_birth'].fillna(1800, inplace=True)\n",
    "\n",
    "test_data['policy_holder_expert_id'].fillna(\"MISSING\", inplace=True)\n",
    "#policy_holder_expert_id_count = train_data['policy_holder_expert_id'].value_counts()\n",
    "#policy_holder_expert_id_count['MISSING'] = 0\n",
    "test_data = test_data.merge(policy_holder_expert_id_count, how='left', \n",
    "                              left_on='policy_holder_expert_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver variables\n",
    "\n",
    "#driver_id_count = train_data['driver_id'].value_counts()\n",
    "test_data = test_data.merge(driver_id_count, how='left', \n",
    "                              left_on='driver_id', right_index=True)\n",
    "\n",
    "test_data['driver_postal_code'].fillna(0, inplace=True)\n",
    "#driver_postal_code_count = train_data['driver_postal_code'].value_counts()\n",
    "#driver_postal_code_count.loc[0] = 0\n",
    "test_data = test_data.merge(driver_postal_code_count, how='left', \n",
    "                              left_on='driver_postal_code', right_index=True)\n",
    "\n",
    "test_data['driver_year_birth'].fillna(1801, inplace=True)\n",
    "\n",
    "test_data['driver_expert_id'].fillna(\"MISSING\", inplace=True)\n",
    "#driver_expert_id_count = train_data['driver_expert_id'].value_counts()\n",
    "#driver_expert_id_count['MISSING'] = 0\n",
    "test_data = test_data.merge(driver_expert_id_count, how='left', \n",
    "                              left_on='driver_expert_id', right_index=True)\n",
    "\n",
    "test_data['driver_vehicle_id'].fillna(\"MISSING\", inplace=True)\n",
    "#driver_vehicle_id_count = train_data['driver_vehicle_id'].value_counts()\n",
    "#driver_vehicle_id_count[\"MISSING\"] = 0\n",
    "test_data = test_data.merge(driver_vehicle_id_count, how='left', \n",
    "                              left_on='driver_vehicle_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party 1st variables\n",
    "\n",
    "test_data['third_party_1_id'].fillna(\"MISSING\", inplace=True)\n",
    "#third_party_1_id_count = train_data['third_party_1_id'].value_counts()\n",
    "#third_party_1_id_count[\"MISSING\"] = 0\n",
    "test_data = test_data.merge(third_party_1_id_count, how='left', \n",
    "                              left_on='third_party_1_id', right_index=True)\n",
    "\n",
    "test_data['third_party_1_postal_code'].fillna(0, inplace=True)\n",
    "#third_party_1_postal_code_count = train_data['third_party_1_postal_code'].value_counts()\n",
    "#third_party_1_postal_code_count[0] = 0\n",
    "test_data = test_data.merge(third_party_1_postal_code_count, how='left', \n",
    "                              left_on='third_party_1_postal_code', right_index=True)\n",
    "\n",
    "test_data['third_party_1_injured'].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "test_data['third_party_1_vehicle_type'].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "test_data['third_party_1_form'].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "test_data['third_party_1_year_birth'].fillna(1802, inplace=True)\n",
    "\n",
    "test_data['third_party_1_country'].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "test_data['third_party_1_vehicle_id'].fillna(\"MISSING\", inplace=True)\n",
    "#third_party_1_vehicle_id_count = train_data['third_party_1_vehicle_id'].value_counts()\n",
    "#third_party_1_vehicle_id_count[\"MISSING\"] = 0\n",
    "test_data = test_data.merge(third_party_1_vehicle_id_count, how='left', \n",
    "                              left_on='third_party_1_vehicle_id', right_index=True)\n",
    "\n",
    "test_data['third_party_1_expert_id'].fillna(\"MISSING\", inplace=True)\n",
    "#third_party_1_expert_id_count = train_data['third_party_1_expert_id'].value_counts()\n",
    "#third_party_1_expert_id_count[\"MISSING\"] = 0\n",
    "test_data = test_data.merge(third_party_1_expert_id_count, how='left', \n",
    "                 left_on='third_party_1_expert_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party rest of variables\n",
    "\n",
    "mask = test_data['third_party_2_id'].isna()\n",
    "test_data.loc[mask, 'third_party_2_id'] = 0\n",
    "test_data.loc[~mask, 'third_party_2_id'] = 1\n",
    "\n",
    "mask = test_data['third_party_2_postal_code'].isna()\n",
    "test_data.loc[mask, 'third_party_2_postal_code'] = 0\n",
    "test_data.loc[~mask, 'third_party_2_postal_code'] = 1\n",
    "\n",
    "mask = test_data['third_party_2_injured'].isna()\n",
    "test_data.loc[mask, 'third_party_2_injured'] = 0\n",
    "test_data.loc[~mask, 'third_party_2_injured'] = 1\n",
    "\n",
    "mask = test_data['third_party_2_vehicle_type'].isna()\n",
    "test_data.loc[mask, 'third_party_2_vehicle_type'] = 0\n",
    "test_data.loc[~mask, 'third_party_2_vehicle_type'] = 1\n",
    "\n",
    "mask = test_data['third_party_2_form'].isna()\n",
    "test_data.loc[mask, 'third_party_2_form'] = 0\n",
    "test_data.loc[~mask, 'third_party_2_form'] = 1\n",
    "\n",
    "mask = test_data['third_party_2_year_birth'].isna()\n",
    "test_data.loc[mask, 'third_party_2_year_birth'] = 0\n",
    "test_data.loc[~mask, 'third_party_2_year_birth'] = 1\n",
    "\n",
    "mask = test_data['third_party_2_country'].isna()\n",
    "test_data.loc[mask, 'third_party_2_country'] = 0\n",
    "test_data.loc[~mask, 'third_party_2_country'] = 1\n",
    "\n",
    "mask = test_data['third_party_2_vehicle_id'].isna()\n",
    "test_data.loc[mask, 'third_party_2_vehicle_id'] = 0\n",
    "test_data.loc[~mask, 'third_party_2_vehicle_id'] = 1\n",
    "\n",
    "mask = test_data['third_party_2_expert_id'].isna()\n",
    "test_data.loc[mask, 'third_party_2_expert_id'] = 0\n",
    "test_data.loc[~mask, 'third_party_2_expert_id'] = 1\n",
    "\n",
    "mask = test_data['third_party_3_id'].isna()\n",
    "test_data.loc[mask, 'third_party_3_id'] = 0\n",
    "test_data.loc[~mask, 'third_party_3_id'] = 1\n",
    "\n",
    "mask = test_data['third_party_3_postal_code'].isna()\n",
    "test_data.loc[mask, 'third_party_3_postal_code'] = 0\n",
    "test_data.loc[~mask, 'third_party_3_postal_code'] = 1\n",
    "\n",
    "mask = test_data['third_party_3_injured'].isna()\n",
    "test_data.loc[mask, 'third_party_3_injured'] = 0\n",
    "test_data.loc[~mask, 'third_party_3_injured'] = 1\n",
    "\n",
    "mask = test_data['third_party_3_vehicle_type'].isna()\n",
    "test_data.loc[mask, 'third_party_3_vehicle_type'] = 0\n",
    "test_data.loc[~mask, 'third_party_3_vehicle_type'] = 1\n",
    "\n",
    "mask = test_data['third_party_3_form'].isna()\n",
    "test_data.loc[mask, 'third_party_3_form'] = 0\n",
    "test_data.loc[~mask, 'third_party_3_form'] = 1\n",
    "\n",
    "mask = test_data['third_party_3_year_birth'].isna()\n",
    "test_data.loc[mask, 'third_party_3_year_birth'] = 0\n",
    "test_data.loc[~mask, 'third_party_3_year_birth'] = 1\n",
    "\n",
    "mask = test_data['third_party_3_country'].isna()\n",
    "test_data.loc[mask, 'third_party_3_country'] = 0\n",
    "test_data.loc[~mask, 'third_party_3_country'] = 1\n",
    "\n",
    "mask = test_data['third_party_3_vehicle_id'].isna()\n",
    "test_data.loc[mask, 'third_party_3_vehicle_id'] = 0\n",
    "test_data.loc[~mask, 'third_party_3_vehicle_id'] = 1\n",
    "\n",
    "mask = test_data['third_party_3_expert_id'].isna()\n",
    "test_data.loc[mask, 'third_party_3_expert_id'] = 0\n",
    "test_data.loc[~mask, 'third_party_3_expert_id'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repair variables\n",
    "\n",
    "test_data['repair_id'].fillna(\"MISSING\", inplace=True)\n",
    "#repair_id_count = train_data['repair_id'].value_counts()\n",
    "#repair_id_count[\"MISSING\"] = 0\n",
    "test_data = test_data.merge(repair_id_count, how='left', \n",
    "                 left_on='repair_id', right_index=True)\n",
    "\n",
    "test_data['repair_postal_code'].fillna(0, inplace=True)\n",
    "#repair_postal_code_count = train_data['repair_postal_code'].value_counts()\n",
    "#repair_postal_code_count[0] = 0\n",
    "test_data = test_data.merge(repair_postal_code_count, how='left', \n",
    "                 left_on='repair_postal_code', right_index=True)\n",
    "\n",
    "test_data['repair_form'].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "test_data['repair_year_birth'].fillna(1804, inplace=True)\n",
    "\n",
    "test_data['repair_country'].fillna(\"MISSING\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final variables\n",
    "\n",
    "test_data['policy_date_start'].fillna(180501, inplace=True)\n",
    "test_data['policy_date_start'] = pd.to_datetime(test_data['policy_date_start'].astype(int).astype(str),\n",
    "                                                 format='%Y%m')\n",
    "\n",
    "test_data['policy_date_next_expiry'].fillna(180501, inplace=True)\n",
    "test_data['policy_date_next_expiry'] = pd.to_datetime(test_data['policy_date_next_expiry'].astype(int).astype(str),\n",
    "                                                       format='%Y%m')\n",
    "\n",
    "test_data['policy_date_last_renewed'].fillna(180501, inplace=True)\n",
    "test_data['policy_date_last_renewed'] = pd.to_datetime(test_data['policy_date_last_renewed'].astype(int).astype(str),\n",
    "                                                        format='%Y%m')\n",
    "\n",
    "test_data['policy_premium_100'].fillna(200, inplace=True)\n",
    "\n",
    "test_data['policy_coverage_1000'].fillna(300, inplace=True)\n",
    "\n",
    "test_data['policy_coverage_type'].fillna(\"MISSING\", inplace=True)\n",
    "#policy_coverage_type_count = train_data['policy_coverage_type'].value_counts()\n",
    "#policy_coverage_type_count[\"MISSING\"] = 0\n",
    "test_data = test_data.merge(policy_coverage_type_count, how='left', \n",
    "                 left_on='policy_coverage_type', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop cols for now\n",
    "\n",
    "X_test = test_data.drop(columns=dropcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (X_test.dtypes == object)\n",
    "test_obj = X_test.dtypes.loc[mask].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_obj == train_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictors\n",
    "\n",
    "encoded_predictors = pd.get_dummies(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112,), (112,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "\n",
    "pred_cols = encoded_predictors.columns \n",
    "train_cols.shape, pred_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are cooking baby\n",
    "\n",
    "(train_cols == pred_cols).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf.predict_proba(encoded_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions, index=test_data['claim_id'])\n",
    "#predictions.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[1].to_csv('test_proba_8.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
