{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_id</th>\n",
       "      <th>fraud</th>\n",
       "      <th>claim_amount</th>\n",
       "      <th>claim_date_registered</th>\n",
       "      <th>claim_date_occured</th>\n",
       "      <th>claim_time_occured</th>\n",
       "      <th>claim_postal_code</th>\n",
       "      <th>claim_cause</th>\n",
       "      <th>claim_liable</th>\n",
       "      <th>claim_num_injured</th>\n",
       "      <th>...</th>\n",
       "      <th>repair_country</th>\n",
       "      <th>repair_sla</th>\n",
       "      <th>policy_date_start</th>\n",
       "      <th>policy_date_next_expiry</th>\n",
       "      <th>policy_date_last_renewed</th>\n",
       "      <th>policy_num_changes</th>\n",
       "      <th>policy_num_claims</th>\n",
       "      <th>policy_premium_100</th>\n",
       "      <th>policy_coverage_1000</th>\n",
       "      <th>policy_coverage_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>N</td>\n",
       "      <td>4895,00</td>\n",
       "      <td>20170101</td>\n",
       "      <td>20161229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>traffic accident</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>201604.0</td>\n",
       "      <td>201704.0</td>\n",
       "      <td>201704.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#000111000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>N</td>\n",
       "      <td>3249,81</td>\n",
       "      <td>20170101</td>\n",
       "      <td>20161223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8820</td>\n",
       "      <td>traffic accident</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>B</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>N</td>\n",
       "      <td>3242,89</td>\n",
       "      <td>20170101</td>\n",
       "      <td>20161228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1831</td>\n",
       "      <td>traffic accident</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>200704.0</td>\n",
       "      <td>201704.0</td>\n",
       "      <td>201704.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>#111110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>N</td>\n",
       "      <td>2687,00</td>\n",
       "      <td>20170101</td>\n",
       "      <td>20161228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2610</td>\n",
       "      <td>traffic accident</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>199808.0</td>\n",
       "      <td>201708.0</td>\n",
       "      <td>201708.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#000110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>N</td>\n",
       "      <td>2084,45</td>\n",
       "      <td>20170101</td>\n",
       "      <td>20161229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1210</td>\n",
       "      <td>traffic accident</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>200608.0</td>\n",
       "      <td>201708.0</td>\n",
       "      <td>201708.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>#111110110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   claim_id fraud claim_amount  claim_date_registered  claim_date_occured  \\\n",
       "0     10000     N      4895,00               20170101            20161229   \n",
       "1     10001     N      3249,81               20170101            20161223   \n",
       "2     10002     N      3242,89               20170101            20161228   \n",
       "3     10003     N      2687,00               20170101            20161228   \n",
       "4     10004     N      2084,45               20170101            20161229   \n",
       "\n",
       "   claim_time_occured  claim_postal_code       claim_cause claim_liable  \\\n",
       "0                 NaN               2018  traffic accident            Y   \n",
       "1                 NaN               8820  traffic accident            N   \n",
       "2                 NaN               1831  traffic accident            Y   \n",
       "3                 NaN               2610  traffic accident            Y   \n",
       "4                 NaN               1210  traffic accident            Y   \n",
       "\n",
       "   claim_num_injured  ...  repair_country  repair_sla policy_date_start  \\\n",
       "0                  1  ...             NaN           N          201604.0   \n",
       "1                  0  ...               B           Y               NaN   \n",
       "2                  0  ...             NaN           N          200704.0   \n",
       "3                  0  ...             NaN           N          199808.0   \n",
       "4                  0  ...             NaN           N          200608.0   \n",
       "\n",
       "  policy_date_next_expiry  policy_date_last_renewed policy_num_changes  \\\n",
       "0                201704.0                  201704.0                  1   \n",
       "1                     NaN                       NaN                  0   \n",
       "2                201704.0                  201704.0                  0   \n",
       "3                201708.0                  201708.0                  0   \n",
       "4                201708.0                  201708.0                  0   \n",
       "\n",
       "  policy_num_claims policy_premium_100  policy_coverage_1000  \\\n",
       "0                 0                4.0                   NaN   \n",
       "1                 0                NaN                   NaN   \n",
       "2                 0               20.0                  58.0   \n",
       "3                 8                4.0                   NaN   \n",
       "4                 9               19.0                  15.0   \n",
       "\n",
       "   policy_coverage_type  \n",
       "0            #000111000  \n",
       "1            #000000000  \n",
       "2            #111110000  \n",
       "3            #000110000  \n",
       "4            #111110110  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read training data\n",
    "\n",
    "train_data = pd.read_csv('train.csv', delimiter=';')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29955, 76)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read test data\n",
    "\n",
    "test_data = pd.read_csv('test.csv', delimiter=';')\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# claim variables\n",
    "\n",
    "train_data['claim_amount'] = train_data['claim_amount'].str.replace(',','.').astype('float64')\n",
    "\n",
    "train_data['claim_date_registered'] = pd.to_datetime(train_data['claim_date_registered'], format='%Y%m%d')\n",
    "\n",
    "train_data['claim_date_occured'] = pd.to_datetime(train_data['claim_date_occured'], format='%Y%m%d')\n",
    "\n",
    "mask_night = (train_data['claim_time_occured'] >= 2200) | (train_data['claim_time_occured'] <= 700)\n",
    "train_data.loc[~mask_night, 'claim_time_occured'] = 0\n",
    "train_data.loc[mask_night, 'claim_time_occured'] = 1\n",
    "\n",
    "postal_code_counts = train_data['claim_postal_code'].value_counts()\n",
    "train_data = train_data.merge(postal_code_counts, how='left', left_on='claim_postal_code', right_index=True)\n",
    "\n",
    "train_data['claim_alcohol'].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "train_data['claim_language'].fillna(\"MISSING\", inplace=True)\n",
    "mask = train_data['claim_language'] == 1.0\n",
    "train_data.loc[mask, 'claim_language'] = \"LANG A\"\n",
    "mask = train_data['claim_language'] == 2.0\n",
    "train_data.loc[mask, 'claim_language'] = \"LANG B\"\n",
    "\n",
    "train_data['claim_vehicle_id'].fillna(\"MISSING\", inplace=True)\n",
    "claim_vehicle_id_count = train_data['claim_vehicle_id'].value_counts()\n",
    "claim_vehicle_id_count[\"MISSING\"] = 0\n",
    "train_data = train_data.merge(claim_vehicle_id_count, how='left', \n",
    "                              left_on='claim_vehicle_id', right_index=True)\n",
    "\n",
    "train_data['claim_vehicle_brand'].fillna('MISSING', inplace=True)\n",
    "claim_vehicle_brand_counts = train_data['claim_vehicle_brand'].value_counts()\n",
    "claim_vehicle_brand_counts['MISSING'] = 0\n",
    "train_data = train_data.merge(claim_vehicle_brand_counts, how='left', \n",
    "                              left_on='claim_vehicle_brand', right_index=True)\n",
    "\n",
    "\n",
    "train_data['claim_vehicle_type'].fillna('MISSING', inplace=True)\n",
    "\n",
    "train_data['claim_vehicle_date_inuse'].fillna(190001, inplace=True)\n",
    "train_data['claim_vehicle_date_inuse'] = train_data['claim_vehicle_date_inuse'].astype(int)\n",
    "mask = (train_data['claim_vehicle_date_inuse'] > 220000)\n",
    "train_data.loc[mask, 'claim_vehicle_date_inuse'] = 190001\n",
    "train_data['claim_vehicle_date_inuse'] = pd.to_datetime(train_data['claim_vehicle_date_inuse'].astype(str), \n",
    "                                                        format='%Y%m')\n",
    "\n",
    "train_data['claim_vehicle_cyl'].fillna(10000, inplace=True)\n",
    "\n",
    "train_data['claim_vehicle_load'].fillna(500, inplace=True)\n",
    "\n",
    "train_data['claim_vehicle_fuel_type'].fillna('MISSING', inplace=True)\n",
    "mask = train_data['claim_vehicle_fuel_type'] == 1.0\n",
    "train_data.loc[mask, 'claim_vehicle_fuel_type'] = \"FUEL A\"\n",
    "mask = train_data['claim_vehicle_fuel_type'] == 2.0\n",
    "train_data.loc[mask, 'claim_vehicle_fuel_type'] = \"FUEL B\"\n",
    "\n",
    "train_data['claim_vehicle_power'].fillna(1000, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy variables\n",
    "\n",
    "policy_holder_id_count = train_data['policy_holder_id'].value_counts()\n",
    "train_data = train_data.merge(policy_holder_id_count, how='left', \n",
    "                              left_on='policy_holder_id', right_index=True)\n",
    "\n",
    "train_data['policy_holder_postal_code'].fillna(0, inplace=True)\n",
    "policy_holder_postal_code_counts = train_data['policy_holder_postal_code'].value_counts()\n",
    "policy_holder_postal_code_counts.loc[0] = 0\n",
    "train_data = train_data.merge(policy_holder_postal_code_counts, how='left', \n",
    "                              left_on='policy_holder_postal_code', right_index=True)\n",
    "\n",
    "train_data['policy_holder_year_birth'].fillna(1800, inplace=True)\n",
    "\n",
    "train_data['policy_holder_expert_id'].fillna(\"MISSING\", inplace=True)\n",
    "policy_holder_expert_id_count = train_data['policy_holder_expert_id'].value_counts()\n",
    "policy_holder_expert_id_count['MISSING'] = 0\n",
    "train_data = train_data.merge(policy_holder_expert_id_count, how='left', \n",
    "                              left_on='policy_holder_expert_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver variables\n",
    "\n",
    "driver_id_count = train_data['driver_id'].value_counts()\n",
    "train_data = train_data.merge(driver_id_count, how='left', \n",
    "                              left_on='driver_id', right_index=True)\n",
    "\n",
    "train_data['driver_postal_code'].fillna(0, inplace=True)\n",
    "driver_postal_code_count = train_data['driver_postal_code'].value_counts()\n",
    "driver_postal_code_count.loc[0] = 0\n",
    "train_data = train_data.merge(driver_postal_code_count, how='left', \n",
    "                              left_on='driver_postal_code', right_index=True)\n",
    "\n",
    "train_data['driver_year_birth'].fillna(1801, inplace=True)\n",
    "\n",
    "train_data['driver_expert_id'].fillna(\"MISSING\", inplace=True)\n",
    "driver_expert_id_count = train_data['driver_expert_id'].value_counts()\n",
    "driver_expert_id_count['MISSING'] = 0\n",
    "train_data = train_data.merge(driver_expert_id_count, how='left', \n",
    "                              left_on='driver_expert_id', right_index=True)\n",
    "\n",
    "train_data['driver_vehicle_id'].fillna(\"MISSING\", inplace=True)\n",
    "driver_vehicle_id_count = train_data['driver_vehicle_id'].value_counts()\n",
    "driver_vehicle_id_count[\"MISSING\"] = 0\n",
    "train_data = train_data.merge(driver_vehicle_id_count, how='left', \n",
    "                              left_on='driver_vehicle_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party 1st variables\n",
    "\n",
    "train_data['third_party_1_id'].fillna(\"MISSING\", inplace=True)\n",
    "third_party_1_id_count = train_data['third_party_1_id'].value_counts()\n",
    "third_party_1_id_count[\"MISSING\"] = 0\n",
    "train_data = train_data.merge(third_party_1_id_count, how='left', \n",
    "                              left_on='third_party_1_id', right_index=True)\n",
    "\n",
    "train_data['third_party_1_postal_code'].fillna(0, inplace=True)\n",
    "third_party_1_postal_code_count = train_data['third_party_1_postal_code'].value_counts()\n",
    "third_party_1_postal_code_count[0] = 0\n",
    "train_data = train_data.merge(third_party_1_postal_code_count, how='left', \n",
    "                              left_on='third_party_1_postal_code', right_index=True)\n",
    "\n",
    "train_data['third_party_1_injured'].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "train_data['third_party_1_vehicle_type'].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "train_data['third_party_1_form'].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "train_data['third_party_1_year_birth'].fillna(1802, inplace=True)\n",
    "\n",
    "train_data['third_party_1_country'].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "train_data['third_party_1_vehicle_id'].fillna(\"MISSING\", inplace=True)\n",
    "third_party_1_vehicle_id_count = train_data['third_party_1_vehicle_id'].value_counts()\n",
    "third_party_1_vehicle_id_count[\"MISSING\"] = 0\n",
    "train_data = train_data.merge(third_party_1_vehicle_id_count, how='left', \n",
    "                              left_on='third_party_1_vehicle_id', right_index=True)\n",
    "\n",
    "train_data['third_party_1_expert_id'].fillna(\"MISSING\", inplace=True)\n",
    "third_party_1_expert_id_count = train_data['third_party_1_expert_id'].value_counts()\n",
    "third_party_1_expert_id_count[\"MISSING\"] = 0\n",
    "train_data = train_data.merge(third_party_1_expert_id_count, how='left', \n",
    "                 left_on='third_party_1_expert_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party rest of variables\n",
    "\n",
    "mask = train_data['third_party_2_id'].isna()\n",
    "train_data.loc[mask, 'third_party_2_id'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_id'] = 1\n",
    "\n",
    "mask = train_data['third_party_2_postal_code'].isna()\n",
    "train_data.loc[mask, 'third_party_2_postal_code'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_postal_code'] = 1\n",
    "\n",
    "mask = train_data['third_party_2_injured'].isna()\n",
    "train_data.loc[mask, 'third_party_2_injured'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_injured'] = 1\n",
    "\n",
    "mask = train_data['third_party_2_vehicle_type'].isna()\n",
    "train_data.loc[mask, 'third_party_2_vehicle_type'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_vehicle_type'] = 1\n",
    "\n",
    "mask = train_data['third_party_2_form'].isna()\n",
    "train_data.loc[mask, 'third_party_2_form'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_form'] = 1\n",
    "\n",
    "mask = train_data['third_party_2_year_birth'].isna()\n",
    "train_data.loc[mask, 'third_party_2_year_birth'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_year_birth'] = 1\n",
    "\n",
    "mask = train_data['third_party_2_country'].isna()\n",
    "train_data.loc[mask, 'third_party_2_country'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_country'] = 1\n",
    "\n",
    "mask = train_data['third_party_2_vehicle_id'].isna()\n",
    "train_data.loc[mask, 'third_party_2_vehicle_id'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_vehicle_id'] = 1\n",
    "\n",
    "mask = train_data['third_party_2_expert_id'].isna()\n",
    "train_data.loc[mask, 'third_party_2_expert_id'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_expert_id'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_id'].isna()\n",
    "train_data.loc[mask, 'third_party_3_id'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_id'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_postal_code'].isna()\n",
    "train_data.loc[mask, 'third_party_3_postal_code'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_postal_code'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_injured'].isna()\n",
    "train_data.loc[mask, 'third_party_3_injured'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_injured'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_vehicle_type'].isna()\n",
    "train_data.loc[mask, 'third_party_3_vehicle_type'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_vehicle_type'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_form'].isna()\n",
    "train_data.loc[mask, 'third_party_3_form'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_form'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_year_birth'].isna()\n",
    "train_data.loc[mask, 'third_party_3_year_birth'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_year_birth'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_country'].isna()\n",
    "train_data.loc[mask, 'third_party_3_country'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_country'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_vehicle_id'].isna()\n",
    "train_data.loc[mask, 'third_party_3_vehicle_id'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_vehicle_id'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_expert_id'].isna()\n",
    "train_data.loc[mask, 'third_party_3_expert_id'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_expert_id'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repair variables\n",
    "\n",
    "train_data['repair_id'].fillna(\"MISSING\", inplace=True)\n",
    "repair_id_count = train_data['repair_id'].value_counts()\n",
    "repair_id_count[\"MISSING\"] = 0\n",
    "train_data = train_data.merge(repair_id_count, how='left', \n",
    "                 left_on='repair_id', right_index=True)\n",
    "\n",
    "train_data['repair_postal_code'].fillna(0, inplace=True)\n",
    "repair_postal_code_count = train_data['repair_postal_code'].value_counts()\n",
    "repair_postal_code_count[0] = 0\n",
    "train_data = train_data.merge(repair_postal_code_count, how='left', \n",
    "                 left_on='repair_postal_code', right_index=True)\n",
    "\n",
    "train_data['repair_form'].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "train_data['repair_year_birth'].fillna(1804, inplace=True)\n",
    "\n",
    "train_data['repair_country'].fillna(\"MISSING\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final variables\n",
    "\n",
    "train_data['policy_date_start'].fillna(180501, inplace=True)\n",
    "train_data['policy_date_start'] = pd.to_datetime(train_data['policy_date_start'].astype(int).astype(str),\n",
    "                                                 format='%Y%m')\n",
    "\n",
    "train_data['policy_date_next_expiry'].fillna(180501, inplace=True)\n",
    "train_data['policy_date_next_expiry'] = pd.to_datetime(train_data['policy_date_next_expiry'].astype(int).astype(str),\n",
    "                                                       format='%Y%m')\n",
    "\n",
    "train_data['policy_date_last_renewed'].fillna(180501, inplace=True)\n",
    "train_data['policy_date_last_renewed'] = pd.to_datetime(train_data['policy_date_last_renewed'].astype(int).astype(str),\n",
    "                                                        format='%Y%m')\n",
    "\n",
    "train_data['policy_premium_100'].fillna(200, inplace=True)\n",
    "\n",
    "train_data['policy_coverage_1000'].fillna(300, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop cols for now\n",
    "\n",
    "dropcols = ['claim_id', 'claim_postal_code_x', 'claim_vehicle_id_x',\n",
    "       'policy_holder_id_x', 'policy_holder_postal_code_x',\n",
    "       'policy_holder_expert_id_x', 'driver_id_x', 'driver_postal_code_x',\n",
    "       'driver_expert_id_x', 'driver_vehicle_id_x', 'third_party_1_id_x',\n",
    "       'third_party_1_postal_code_x', 'third_party_1_vehicle_id_x',\n",
    "       'third_party_1_expert_id_x', 'repair_id_x', 'repair_postal_code_x',\n",
    "       'claim_date_registered', 'claim_date_occured', 'claim_vehicle_date_inuse',\n",
    "       'policy_date_start', 'policy_date_next_expiry', 'policy_date_last_renewed']\n",
    "\n",
    "clean_data = train_data.drop(columns=dropcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target and covariates\n",
    "\n",
    "y = clean_data['fraud']\n",
    "amount = clean_data['claim_amount']\n",
    "X = clean_data.drop(columns=['fraud', 'claim_amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode vars\n",
    "\n",
    "encoded_covariates = pd.get_dummies(X)\n",
    "encoded_target = pd.get_dummies(y)['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run model\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(encoded_covariates, encoded_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(encoded_covariates, encoded_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29955, 76)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read test data\n",
    "\n",
    "train_data = pd.read_csv('test.csv', delimiter=';')\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# claim variables\n",
    "\n",
    "#train_data['claim_amount'] = train_data['claim_amount'].str.replace(',','.').astype('float64')\n",
    "\n",
    "train_data['claim_date_registered'] = pd.to_datetime(train_data['claim_date_registered'], format='%Y%m%d')\n",
    "\n",
    "train_data['claim_date_occured'] = pd.to_datetime(train_data['claim_date_occured'], format='%Y%m%d')\n",
    "\n",
    "mask_night = (train_data['claim_time_occured'] >= 2200) | (train_data['claim_time_occured'] <= 700)\n",
    "train_data.loc[~mask_night, 'claim_time_occured'] = 0\n",
    "train_data.loc[mask_night, 'claim_time_occured'] = 1\n",
    "\n",
    "postal_code_counts = train_data['claim_postal_code'].value_counts()\n",
    "train_data = train_data.merge(postal_code_counts, how='left', left_on='claim_postal_code', right_index=True)\n",
    "\n",
    "train_data['claim_alcohol'].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "train_data['claim_language'].fillna(\"MISSING\", inplace=True)\n",
    "mask = train_data['claim_language'] == 1.0\n",
    "train_data.loc[mask, 'claim_language'] = \"LANG A\"\n",
    "mask = train_data['claim_language'] == 2.0\n",
    "train_data.loc[mask, 'claim_language'] = \"LANG B\"\n",
    "\n",
    "train_data['claim_vehicle_id'].fillna(\"MISSING\", inplace=True)\n",
    "claim_vehicle_id_count = train_data['claim_vehicle_id'].value_counts()\n",
    "claim_vehicle_id_count[\"MISSING\"] = 0\n",
    "train_data = train_data.merge(claim_vehicle_id_count, how='left', \n",
    "                              left_on='claim_vehicle_id', right_index=True)\n",
    "\n",
    "train_data['claim_vehicle_brand'].fillna('MISSING', inplace=True)\n",
    "claim_vehicle_brand_counts = train_data['claim_vehicle_brand'].value_counts()\n",
    "claim_vehicle_brand_counts['MISSING'] = 0\n",
    "train_data = train_data.merge(claim_vehicle_brand_counts, how='left', \n",
    "                              left_on='claim_vehicle_brand', right_index=True)\n",
    "\n",
    "train_data['claim_vehicle_date_inuse'].fillna(190001, inplace=True)\n",
    "train_data['claim_vehicle_date_inuse'] = train_data['claim_vehicle_date_inuse'].astype(int)\n",
    "mask = (train_data['claim_vehicle_date_inuse'] > 220000)\n",
    "train_data.loc[mask, 'claim_vehicle_date_inuse'] = 190001\n",
    "train_data['claim_vehicle_date_inuse'] = pd.to_datetime(train_data['claim_vehicle_date_inuse'].astype(str), \n",
    "                                                        format='%Y%m')\n",
    "\n",
    "train_data['claim_vehicle_cyl'].fillna(10000, inplace=True)\n",
    "\n",
    "train_data['claim_vehicle_load'].fillna(500, inplace=True)\n",
    "\n",
    "train_data['claim_vehicle_fuel_type'].fillna('MISSING', inplace=True)\n",
    "mask = train_data['claim_vehicle_fuel_type'] == 1.0\n",
    "train_data.loc[mask, 'claim_vehicle_fuel_type'] = \"FUEL A\"\n",
    "mask = train_data['claim_vehicle_fuel_type'] == 2.0\n",
    "train_data.loc[mask, 'claim_vehicle_fuel_type'] = \"FUEL B\"\n",
    "\n",
    "train_data['claim_vehicle_power'].fillna(1000, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy variables\n",
    "\n",
    "policy_holder_id_count = train_data['policy_holder_id'].value_counts()\n",
    "train_data = train_data.merge(policy_holder_id_count, how='left', \n",
    "                              left_on='policy_holder_id', right_index=True)\n",
    "\n",
    "train_data['policy_holder_postal_code'].fillna(0, inplace=True)\n",
    "policy_holder_postal_code_counts = train_data['policy_holder_postal_code'].value_counts()\n",
    "policy_holder_postal_code_counts.loc[0] = 0\n",
    "train_data = train_data.merge(policy_holder_postal_code_counts, how='left', \n",
    "                              left_on='policy_holder_postal_code', right_index=True)\n",
    "\n",
    "train_data['policy_holder_year_birth'].fillna(1800, inplace=True)\n",
    "\n",
    "train_data['policy_holder_expert_id'].fillna(\"MISSING\", inplace=True)\n",
    "policy_holder_expert_id_count = train_data['policy_holder_expert_id'].value_counts()\n",
    "policy_holder_expert_id_count['MISSING'] = 0\n",
    "train_data = train_data.merge(policy_holder_expert_id_count, how='left', \n",
    "                              left_on='policy_holder_expert_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver variables\n",
    "\n",
    "driver_id_count = train_data['driver_id'].value_counts()\n",
    "train_data = train_data.merge(driver_id_count, how='left', \n",
    "                              left_on='driver_id', right_index=True)\n",
    "\n",
    "train_data['driver_postal_code'].fillna(0, inplace=True)\n",
    "driver_postal_code_count = train_data['driver_postal_code'].value_counts()\n",
    "driver_postal_code_count.loc[0] = 0\n",
    "train_data = train_data.merge(driver_postal_code_count, how='left', \n",
    "                              left_on='driver_postal_code', right_index=True)\n",
    "\n",
    "train_data['driver_year_birth'].fillna(1801, inplace=True)\n",
    "\n",
    "train_data['driver_expert_id'].fillna(\"MISSING\", inplace=True)\n",
    "driver_expert_id_count = train_data['driver_expert_id'].value_counts()\n",
    "driver_expert_id_count['MISSING'] = 0\n",
    "train_data = train_data.merge(driver_expert_id_count, how='left', \n",
    "                              left_on='driver_expert_id', right_index=True)\n",
    "\n",
    "train_data['driver_vehicle_id'].fillna(\"MISSING\", inplace=True)\n",
    "driver_vehicle_id_count = train_data['driver_vehicle_id'].value_counts()\n",
    "driver_vehicle_id_count[\"MISSING\"] = 0\n",
    "train_data = train_data.merge(driver_vehicle_id_count, how='left', \n",
    "                              left_on='driver_vehicle_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party 1st variables\n",
    "\n",
    "train_data['third_party_1_id'].fillna(\"MISSING\", inplace=True)\n",
    "third_party_1_id_count = train_data['third_party_1_id'].value_counts()\n",
    "third_party_1_id_count[\"MISSING\"] = 0\n",
    "train_data = train_data.merge(third_party_1_id_count, how='left', \n",
    "                              left_on='third_party_1_id', right_index=True)\n",
    "\n",
    "train_data['third_party_1_postal_code'].fillna(0, inplace=True)\n",
    "third_party_1_postal_code_count = train_data['third_party_1_postal_code'].value_counts()\n",
    "third_party_1_postal_code_count[0] = 0\n",
    "train_data = train_data.merge(third_party_1_postal_code_count, how='left', \n",
    "                              left_on='third_party_1_postal_code', right_index=True)\n",
    "\n",
    "train_data['third_party_1_injured'].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "train_data['third_party_1_vehicle_type'].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "train_data['third_party_1_form'].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "train_data['third_party_1_year_birth'].fillna(1802, inplace=True)\n",
    "\n",
    "train_data['third_party_1_country'].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "train_data['third_party_1_vehicle_id'].fillna(\"MISSING\", inplace=True)\n",
    "third_party_1_vehicle_id_count = train_data['third_party_1_vehicle_id'].value_counts()\n",
    "third_party_1_vehicle_id_count[\"MISSING\"] = 0\n",
    "train_data = train_data.merge(third_party_1_vehicle_id_count, how='left', \n",
    "                              left_on='third_party_1_vehicle_id', right_index=True)\n",
    "\n",
    "train_data['third_party_1_expert_id'].fillna(\"MISSING\", inplace=True)\n",
    "third_party_1_expert_id_count = train_data['third_party_1_expert_id'].value_counts()\n",
    "third_party_1_expert_id_count[\"MISSING\"] = 0\n",
    "train_data = train_data.merge(third_party_1_expert_id_count, how='left', \n",
    "                 left_on='third_party_1_expert_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party rest of variables\n",
    "\n",
    "mask = train_data['third_party_2_id'].isna()\n",
    "train_data.loc[mask, 'third_party_2_id'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_id'] = 1\n",
    "\n",
    "mask = train_data['third_party_2_postal_code'].isna()\n",
    "train_data.loc[mask, 'third_party_2_postal_code'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_postal_code'] = 1\n",
    "\n",
    "mask = train_data['third_party_2_injured'].isna()\n",
    "train_data.loc[mask, 'third_party_2_injured'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_injured'] = 1\n",
    "\n",
    "mask = train_data['third_party_2_vehicle_type'].isna()\n",
    "train_data.loc[mask, 'third_party_2_vehicle_type'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_vehicle_type'] = 1\n",
    "\n",
    "mask = train_data['third_party_2_form'].isna()\n",
    "train_data.loc[mask, 'third_party_2_form'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_form'] = 1\n",
    "\n",
    "mask = train_data['third_party_2_year_birth'].isna()\n",
    "train_data.loc[mask, 'third_party_2_year_birth'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_year_birth'] = 1\n",
    "\n",
    "mask = train_data['third_party_2_country'].isna()\n",
    "train_data.loc[mask, 'third_party_2_country'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_country'] = 1\n",
    "\n",
    "mask = train_data['third_party_2_vehicle_id'].isna()\n",
    "train_data.loc[mask, 'third_party_2_vehicle_id'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_vehicle_id'] = 1\n",
    "\n",
    "mask = train_data['third_party_2_expert_id'].isna()\n",
    "train_data.loc[mask, 'third_party_2_expert_id'] = 0\n",
    "train_data.loc[~mask, 'third_party_2_expert_id'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_id'].isna()\n",
    "train_data.loc[mask, 'third_party_3_id'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_id'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_postal_code'].isna()\n",
    "train_data.loc[mask, 'third_party_3_postal_code'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_postal_code'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_injured'].isna()\n",
    "train_data.loc[mask, 'third_party_3_injured'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_injured'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_vehicle_type'].isna()\n",
    "train_data.loc[mask, 'third_party_3_vehicle_type'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_vehicle_type'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_form'].isna()\n",
    "train_data.loc[mask, 'third_party_3_form'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_form'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_year_birth'].isna()\n",
    "train_data.loc[mask, 'third_party_3_year_birth'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_year_birth'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_country'].isna()\n",
    "train_data.loc[mask, 'third_party_3_country'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_country'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_vehicle_id'].isna()\n",
    "train_data.loc[mask, 'third_party_3_vehicle_id'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_vehicle_id'] = 1\n",
    "\n",
    "mask = train_data['third_party_3_expert_id'].isna()\n",
    "train_data.loc[mask, 'third_party_3_expert_id'] = 0\n",
    "train_data.loc[~mask, 'third_party_3_expert_id'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repair variables\n",
    "\n",
    "train_data['repair_id'].fillna(\"MISSING\", inplace=True)\n",
    "repair_id_count = train_data['repair_id'].value_counts()\n",
    "repair_id_count[\"MISSING\"] = 0\n",
    "train_data = train_data.merge(repair_id_count, how='left', \n",
    "                 left_on='repair_id', right_index=True)\n",
    "\n",
    "train_data['repair_postal_code'].fillna(0, inplace=True)\n",
    "repair_postal_code_count = train_data['repair_postal_code'].value_counts()\n",
    "repair_postal_code_count[0] = 0\n",
    "train_data = train_data.merge(repair_postal_code_count, how='left', \n",
    "                 left_on='repair_postal_code', right_index=True)\n",
    "\n",
    "train_data['repair_form'].fillna(\"MISSING\", inplace=True)\n",
    "\n",
    "train_data['repair_year_birth'].fillna(1804, inplace=True)\n",
    "\n",
    "train_data['repair_country'].fillna(\"MISSING\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final variables\n",
    "\n",
    "train_data['policy_date_start'].fillna(180501, inplace=True)\n",
    "train_data['policy_date_start'] = pd.to_datetime(train_data['policy_date_start'].astype(int).astype(str),\n",
    "                                                 format='%Y%m')\n",
    "\n",
    "train_data['policy_date_next_expiry'].fillna(180501, inplace=True)\n",
    "train_data['policy_date_next_expiry'] = pd.to_datetime(train_data['policy_date_next_expiry'].astype(int).astype(str),\n",
    "                                                       format='%Y%m')\n",
    "\n",
    "train_data['policy_date_last_renewed'].fillna(180501, inplace=True)\n",
    "train_data['policy_date_last_renewed'] = pd.to_datetime(train_data['policy_date_last_renewed'].astype(int).astype(str),\n",
    "                                                        format='%Y%m')\n",
    "\n",
    "train_data['policy_premium_100'].fillna(200, inplace=True)\n",
    "\n",
    "train_data['policy_coverage_1000'].fillna(300, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop cols for now\n",
    "\n",
    "dropcols = ['claim_id', 'claim_postal_code_x', 'claim_vehicle_id_x',\n",
    "       'policy_holder_id_x', 'policy_holder_postal_code_x',\n",
    "       'policy_holder_expert_id_x', 'driver_id_x', 'driver_postal_code_x',\n",
    "       'driver_expert_id_x', 'driver_vehicle_id_x', 'third_party_1_id_x',\n",
    "       'third_party_1_postal_code_x', 'third_party_1_vehicle_id_x',\n",
    "       'third_party_1_expert_id_x', 'repair_id_x', 'repair_postal_code_x',\n",
    "       'claim_date_registered', 'claim_date_occured', 'claim_vehicle_date_inuse',\n",
    "       'policy_date_start', 'policy_date_next_expiry', 'policy_date_last_renewed']\n",
    "\n",
    "clean_data = train_data.drop(columns=dropcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target and covariates\n",
    "\n",
    "#y = clean_data['fraud']\n",
    "#amount = clean_data['claim_amount']\n",
    "X = clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_time_occured</th>\n",
       "      <th>claim_cause</th>\n",
       "      <th>claim_liable</th>\n",
       "      <th>claim_num_injured</th>\n",
       "      <th>claim_num_third_parties</th>\n",
       "      <th>claim_num_vehicles</th>\n",
       "      <th>claim_police</th>\n",
       "      <th>claim_alcohol</th>\n",
       "      <th>claim_language</th>\n",
       "      <th>claim_vehicle_brand_x</th>\n",
       "      <th>...</th>\n",
       "      <th>driver_id_y</th>\n",
       "      <th>driver_postal_code_y</th>\n",
       "      <th>driver_expert_id_y</th>\n",
       "      <th>driver_vehicle_id_y</th>\n",
       "      <th>third_party_1_id_y</th>\n",
       "      <th>third_party_1_postal_code_y</th>\n",
       "      <th>third_party_1_vehicle_id_y</th>\n",
       "      <th>third_party_1_expert_id_y</th>\n",
       "      <th>repair_id_y</th>\n",
       "      <th>repair_postal_code_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>traffic accident</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>LANG B</td>\n",
       "      <td>AUDI</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>traffic accident</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>LANG B</td>\n",
       "      <td>FORD</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>traffic accident</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>LANG B</td>\n",
       "      <td>HYUNDAI</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>traffic accident</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>LANG A</td>\n",
       "      <td>RENAULT</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>traffic accident</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>LANG A</td>\n",
       "      <td>VOLKSWAGEN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   claim_time_occured       claim_cause claim_liable  claim_num_injured  \\\n",
       "0                 0.0  traffic accident            Y                  0   \n",
       "1                 0.0  traffic accident            Y                  0   \n",
       "2                 0.0  traffic accident            Y                  0   \n",
       "3                 0.0  traffic accident            Y                  0   \n",
       "4                 0.0  traffic accident            Y                  0   \n",
       "\n",
       "   claim_num_third_parties  claim_num_vehicles claim_police claim_alcohol  \\\n",
       "0                        1                   2            N       MISSING   \n",
       "1                        1                   3            N       MISSING   \n",
       "2                        1                   2            N       MISSING   \n",
       "3                        1                   3            N       MISSING   \n",
       "4                        1                   2            N       MISSING   \n",
       "\n",
       "  claim_language claim_vehicle_brand_x  ... driver_id_y  driver_postal_code_y  \\\n",
       "0         LANG B                  AUDI  ...           1                    45   \n",
       "1         LANG B                  FORD  ...           2                   400   \n",
       "2         LANG B               HYUNDAI  ...           5                    70   \n",
       "3         LANG A               RENAULT  ...           1                     8   \n",
       "4         LANG A            VOLKSWAGEN  ...           1                    17   \n",
       "\n",
       "   driver_expert_id_y driver_vehicle_id_y  third_party_1_id_y  \\\n",
       "0                   0                   1                   1   \n",
       "1                   0                   1                   2   \n",
       "2                   0                   1                   1   \n",
       "3                   0                   1                   4   \n",
       "4                   0                   1                   1   \n",
       "\n",
       "  third_party_1_postal_code_y  third_party_1_vehicle_id_y  \\\n",
       "0                          31                           1   \n",
       "1                          24                           1   \n",
       "2                          28                           1   \n",
       "3                          26                           1   \n",
       "4                          19                           1   \n",
       "\n",
       "  third_party_1_expert_id_y repair_id_y  repair_postal_code_y  \n",
       "0                         0          31                    35  \n",
       "1                         0           0                     0  \n",
       "2                         0           0                     0  \n",
       "3                         0           0                     0  \n",
       "4                         0           0                     0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode vars\n",
    "\n",
    "encoded_covariates = pd.get_dummies(X)\n",
    "#encoded_target = pd.get_dummies(y)['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['claim_time_occured', 'claim_num_injured', 'claim_num_third_parties',\n",
       "       'claim_num_vehicles', 'claim_vehicle_cyl', 'claim_vehicle_load',\n",
       "       'claim_vehicle_power', 'policy_holder_year_birth', 'driver_year_birth',\n",
       "       'third_party_1_year_birth',\n",
       "       ...\n",
       "       'policy_coverage_type_#111110010', 'policy_coverage_type_#111110011',\n",
       "       'policy_coverage_type_#111110100', 'policy_coverage_type_#111110110',\n",
       "       'policy_coverage_type_#111111000', 'policy_coverage_type_#111111001',\n",
       "       'policy_coverage_type_#111111010', 'policy_coverage_type_#111111011',\n",
       "       'policy_coverage_type_#111111100', 'policy_coverage_type_#111111110'],\n",
       "      dtype='object', length=233)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_covariates.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf.predict_proba(encoded_covariates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claim_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65469</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65470</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65471</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65472</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65473</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0     1\n",
       "claim_id            \n",
       "65469     0.99  0.01\n",
       "65470     0.99  0.01\n",
       "65471     0.97  0.03\n",
       "65472     0.96  0.04\n",
       "65473     0.99  0.01"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame(predictions, index=train_data['claim_id'])\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[1].to_csv('test_proba.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
